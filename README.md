# NLP_disaster
NLP models applied to the kaggle dataset NLP_disaster. Three models are proposed:
* lstm model
* lst model + attention
* Bert model

Score the bert model: 0.827

Modified from 'Simple Text Multi Classification Task Using Keras BERT', Analytics Vidhya and Sequence Models, Coursera
 #  Dependencies
 * Tensorflow 2.4.0
 * Python 3.7
 #  User guide
 Set the paths of the following repositories:
* train_path
* test_path
* submission_path
* save_dir

Change 'module_url' to switch for another BERT module

Run main.py to train the models
